name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.9'

jobs:
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    environment: cads-research
    
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          cache-dependency-path: 'requirements.txt'

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Debug environment
        run: |
          echo "Python version: $(python --version)"
          echo "Current directory: $(pwd)"
          echo "Requirements file check:"
          ls -la requirements.txt
          echo "CADS directory check:"
          ls -la cads/ || echo "CADS directory structure may differ in CI"
          echo "Project structure:"
          ls -la

      - name: Set up test environment variables
        run: |
          echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/test_db" >> $GITHUB_ENV
          echo "SUPABASE_URL=${{ secrets.DATABASE_URL }}" >> $GITHUB_ENV
          echo "OPENALEX_EMAIL=test@example.com" >> $GITHUB_ENV
          echo "GROQ_API_KEY=${{ secrets.GROQ_API_KEY }}" >> $GITHUB_ENV
          echo "CI=true" >> $GITHUB_ENV

      - name: Generate comprehensive test data
        run: |
          echo "🔧 Generating comprehensive test data for CI environment..."
          python3 scripts/ci/generate_test_data.py
          
          echo "📋 Verifying generated files..."
          ls -la data/processed/
          ls -la visuals/public/data/
          
          echo "📊 File sizes:"
          find data/ visuals/public/data/ -name "*.json" -exec ls -lh {} \;
          echo "📦 Compressed files:"
          find data/ visuals/public/data/ -name "*.gz" -exec ls -lh {} \;
          
          echo "✅ Comprehensive test data generated successfully"

      - name: Run comprehensive test suite
        run: |
          chmod +x .github/scripts/run-tests.sh
          ./.github/scripts/run-tests.sh

  deploy:
    name: Deploy to Vercel
    needs: test
    runs-on: ubuntu-latest
    environment: cads-research
    # Only deploy if tests pass AND we're on main branch AND it's a push (not PR)
    if: success() && github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Verify test job succeeded
        run: |
          echo "✅ All tests passed successfully - proceeding with deployment"
          echo "Branch: ${{ github.ref }}"
          echo "Event: ${{ github.event_name }}"

      - name: Debug Vercel configuration
        run: |
          echo "🔍 Verifying Vercel environment variables..."
          echo "VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN != '' && 'SET' || 'NOT SET' }}"
          echo "VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID != '' && 'SET' || 'NOT SET' }}"
          echo "VERCEL_PROJECT_ID: ${{ secrets.VERCEL_PROJECT_ID != '' && 'SET' || 'NOT SET' }}"
          echo "Environment: cads-research"

      - name: Install Vercel CLI
        run: npm install -g vercel@latest


      - name: Deploy to Vercel
        run: |
          echo "🚀 Starting Vercel deployment..."
          
          # Verify required environment variables
          if [ -z "$VERCEL_TOKEN" ]; then
            echo "❌ VERCEL_TOKEN is not set"
            exit 1
          fi
          
          echo "✅ Vercel token is set"
          echo "🔧 Using existing Vercel project for consistent URLs..."
          
          # Deploy to existing project with proper configuration
          echo "🚀 Deploying to existing cads-research project..."
          echo "📁 Deploying from directory: visuals/public-prod/"
          
          # Change to the correct directory for deployment
          cd visuals/public-prod/
          
          # Capture the deployment URL from Vercel output
          DEPLOYMENT_OUTPUT=$(vercel --prod --token "$VERCEL_TOKEN" --yes 2>&1)
          echo "$DEPLOYMENT_OUTPUT"
          
          # Extract the production URL from the output
          DEPLOYMENT_URL=$(echo "$DEPLOYMENT_OUTPUT" | grep -E "https://.*\.vercel\.app" | tail -1 | awk '{print $1}')
          
          if [ -z "$DEPLOYMENT_URL" ]; then
            echo "❌ Failed to extract deployment URL from Vercel output"
            echo "Vercel output was:"
            echo "$DEPLOYMENT_OUTPUT"
            exit 1
          fi
          
          echo "✅ Deployment successful!"
          echo "📍 Deployment URL: $DEPLOYMENT_URL"
          
          # Save URL for health check
          echo "DEPLOYMENT_URL=$DEPLOYMENT_URL" >> $GITHUB_ENV
        env:
          VERCEL_TOKEN: ${{ secrets.VERCEL_TOKEN }}
          VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }}
          VERCEL_PROJECT_ID: ${{ secrets.VERCEL_PROJECT_ID }}

      - name: Health check
        run: |
          echo "🏥 Running post-deployment health check..."
          echo "📍 Testing URL: $DEPLOYMENT_URL"
          
          # Function to test an endpoint with retry logic
          test_endpoint() {
            local url="$1"
            local description="$2"
            local max_attempts=5
            local wait_time=15
            
            for attempt in $(seq 1 $max_attempts); do
              echo "🔍 Testing $description (attempt $attempt/$max_attempts)..."
              
              if curl -f -s -w "HTTP %{http_code} | Size: %{size_download} bytes | Time: %{time_total}s\n" "$url" > /dev/null; then
                echo "✅ $description - SUCCESS"
                return 0
              else
                echo "❌ $description - Failed (attempt $attempt/$max_attempts)"
                if [ $attempt -lt $max_attempts ]; then
                  echo "⏳ Waiting ${wait_time}s before retry..."
                  sleep $wait_time
                fi
              fi
            done
            
            echo "💥 $description - All attempts failed"
            return 1
          }
          
          # Wait for initial deployment propagation
          echo "⏳ Waiting 60 seconds for deployment to fully propagate..."
          sleep 60
          
          # Test main page
          test_endpoint "$DEPLOYMENT_URL" "Main page"
          
          # Test data endpoint
          test_endpoint "$DEPLOYMENT_URL/data/visualization-data.json" "Data endpoint"
          
          # Test static assets
          test_endpoint "$DEPLOYMENT_URL/app.js" "JavaScript assets"
          
          echo "🎉 All health checks passed successfully!"
          echo "🚀 Deployment is fully operational at: $DEPLOYMENT_URL"


      - name: Deployment success notification
        run: |
          echo "🚀 Deployment completed successfully!"
          echo "📍 Live URL: $DEPLOYMENT_URL"
          echo "🎯 All health checks passed - application is fully operational"
          echo "📊 Sentry monitoring ready (configured in frontend)"

  # This job runs when tests fail to provide clear feedback
  test-failure-notification:
    name: Test Failure Notification
    needs: test
    runs-on: ubuntu-latest
    if: failure() && github.ref == 'refs/heads/main' && github.event_name == 'push'
    
    steps:
      - name: Test failure notification
        run: |
          echo "❌ Tests failed - deployment blocked!"
          echo "Branch: ${{ github.ref }}"
          echo "Event: ${{ github.event_name }}"
          echo "Please fix the failing tests before deployment can proceed."
          exit 1

  # Summary job that always runs to provide final status
  summary:
    name: Pipeline Summary
    needs: [test, deploy]
    runs-on: ubuntu-latest
    if: always()
    
    steps:
      - name: Pipeline summary
        run: |
          echo "📋 CI/CD Pipeline Summary"
          echo "======================="
          echo "Test Status: ${{ needs.test.result }}"
          echo "Deploy Status: ${{ needs.deploy.result }}"
          echo "Branch: ${{ github.ref }}"
          echo "Event: ${{ github.event_name }}"
          
          if [[ "${{ needs.test.result }}" == "success" ]]; then
            echo "✅ Tests: PASSED"
          else
            echo "❌ Tests: FAILED"
          fi
          
          if [[ "${{ needs.deploy.result }}" == "success" ]]; then
            echo "✅ Deployment: COMPLETED"
          elif [[ "${{ needs.deploy.result }}" == "skipped" ]]; then
            echo "⏭️ Deployment: SKIPPED (not main branch or tests failed)"
          else
            echo "❌ Deployment: FAILED"
          fi